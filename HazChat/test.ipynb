{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Memproses data untuk Laws...\n",
      "‚ö†Ô∏è Folder d:\\01. Bapak\\Github\\HazChat\\test\\data\\regulation tidak ditemukan.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 55\u001b[0m\n\u001b[0;32m     52\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(knowledge_base)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Buat embedding dan FAISS Index\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_texts(chunks, embedding\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Simpan FAISS Index ke disk\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF untuk PDF\n",
    "from docx import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "\n",
    "FAISS_INDEX_PATH = \"faiss_index\"\n",
    "\n",
    "# Fungsi membaca PDF\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Fungsi membaca DOCX\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Fungsi untuk memuat data dari folder\n",
    "def load_knowledge(role):\n",
    "    role_folders = {\"Laws\": \"regulation\", \"Engineering\": \"engineering\"}\n",
    "    BASE_DIR = os.getcwd()\n",
    "    data_folder = os.path.join(BASE_DIR, \"data\", role_folders.get(role, \"data\"))\n",
    "\n",
    "    combined_text = \"\"\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"‚ö†Ô∏è Folder {data_folder} tidak ditemukan.\")\n",
    "        return \"\"\n",
    "\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        if not os.path.isfile(file_path):\n",
    "            continue\n",
    "        \n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            combined_text += read_pdf(file_path) + \"\\n\"\n",
    "        elif file_name.endswith(\".docx\"):\n",
    "            combined_text += read_docx(file_path) + \"\\n\"\n",
    "\n",
    "    return combined_text\n",
    "\n",
    "# Load data hukum dan engineering, lalu split menjadi chunks\n",
    "for role in [\"Laws\", \"Engineering\"]:\n",
    "    print(f\"üîπ Memproses data untuk {role}...\")\n",
    "    knowledge_base = load_knowledge(role)\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_text(knowledge_base)\n",
    "\n",
    "    # Buat embedding dan FAISS Index\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "\n",
    "    # Simpan FAISS Index ke disk\n",
    "    save_path = f\"{FAISS_INDEX_PATH}_{role.lower()}\"\n",
    "    vector_store.save_local(save_path)\n",
    "    print(f\"‚úÖ FAISS Index untuk {role} disimpan di {save_path}\")\n",
    "\n",
    "print(\"‚úÖ Semua FAISS Index telah dibuat.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(knowledge_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "import pickle\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "import anthropic\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# API Keys\n",
    "OPENAI_API_KEY = st.secrets[\"OPENAI_API_KEY\"]\n",
    "ANTHROPIC_API_KEY = st.secrets[\"ANTHROPIC_API_KEY\"]\n",
    "GEMINI_API_KEY = st.secrets[\"GEMINI_API_KEY\"]\n",
    "\n",
    "# Fungsi untuk memuat FAISS yang sudah ada\n",
    "def load_faiss(role):\n",
    "    file_path = f\"faiss_{role}.pkl\"\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Fungsi untuk menjalankan precompute_embeddings.py\n",
    "def run_precompute_embeddings():\n",
    "    os.system(\"python precompute_embeddings.py\")\n",
    "    st.success(\"‚úÖ Embedding selesai! Silakan refresh halaman.\")\n",
    "\n",
    "# Fungsi memuat prompt dari file\n",
    "def load_prompts():\n",
    "    prompt_dir = os.path.join(os.getcwd(), \"add_prompt\")\n",
    "\n",
    "    prompt_engineering_path = os.path.join(prompt_dir, \"prompt_engineering.txt\")\n",
    "    prompt_laws_path = os.path.join(prompt_dir, \"prompt_laws.txt\")\n",
    "\n",
    "    prompt_engineering = open(prompt_engineering_path, \"r\", encoding=\"utf-8\").read() if os.path.exists(prompt_engineering_path) else \"Tidak ada prompt engineering tersedia.\"\n",
    "    prompt_laws = open(prompt_laws_path, \"r\", encoding=\"utf-8\").read() if os.path.exists(prompt_laws_path) else \"Tidak ada prompt laws tersedia.\"\n",
    "\n",
    "    return prompt_engineering, prompt_laws\n",
    "\n",
    "# Memuat prompt\n",
    "prompt_engineering, prompt_laws = load_prompts()\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"HazChat\")\n",
    "role = st.selectbox(\"Pilih Role\", [\"Laws\", \"Engineering\"])\n",
    "provider = st.selectbox(\"Pilih Provider API\", [\"OpenAI\", \"Anthropic\", \"Gemini\"])\n",
    "\n",
    "# **Tombol untuk melakukan embedding ulang**\n",
    "if st.button(\"üîÑ Jalankan Embedding (Jika Ada Data Baru)\"):\n",
    "    run_precompute_embeddings()\n",
    "\n",
    "# Load FAISS\n",
    "vector_store = load_faiss(role)\n",
    "if vector_store:\n",
    "    st.success(f\"‚úÖ Knowledge base untuk {role} berhasil dimuat!\")\n",
    "else:\n",
    "    st.warning(f\"‚ö†Ô∏è Tidak ada knowledge base untuk {role}. Chatbot tetap bisa berjalan hanya dengan prompt bawaan.\")\n",
    "\n",
    "# Fungsi untuk memilih provider\n",
    "def set_provider(provider):\n",
    "    if provider == \"OpenAI\":\n",
    "        return OpenAI(api_key=OPENAI_API_KEY)\n",
    "    elif provider == \"Anthropic\":\n",
    "        return anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "    elif provider == \"Gemini\":\n",
    "        genai.configure(api_key=GEMINI_API_KEY)\n",
    "        return genai\n",
    "    return None\n",
    "\n",
    "# Fungsi untuk mendapatkan respons + menghitung token usage\n",
    "def get_response(provider, client, prompt, role, vector_store, prompt_laws, prompt_engineering):\n",
    "    # Jika FAISS tersedia, gunakan retrieval\n",
    "    if vector_store:\n",
    "        retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "        relevant_docs = retriever.get_relevant_documents(prompt)\n",
    "        context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    else:\n",
    "        context = \"\"\n",
    "\n",
    "    # Jika FAISS tidak ada, hanya gunakan prompt default\n",
    "    if role == \"Laws\":\n",
    "        augmented_prompt = f\"Gunakan informasi berikut jika relevan:\\n{prompt_laws}\\n\\n{context}\\n\\nPertanyaan: {prompt}\"\n",
    "    elif role == \"Engineering\":\n",
    "        augmented_prompt = f\"Gunakan informasi berikut jika relevan:\\n{prompt_engineering}\\n\\n{context}\\n\\nPertanyaan: {prompt}\"\n",
    "    else:\n",
    "        return \"Peran tidak dikenali.\"\n",
    "\n",
    "    try:\n",
    "        token_usage = 0  # Default token usage\n",
    "\n",
    "        if provider == \"OpenAI\":\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": augmented_prompt}]\n",
    "            )\n",
    "            token_usage = response.usage.total_tokens  # OpenAI API memberikan jumlah token\n",
    "            return response.choices[0].message.content, token_usage\n",
    "\n",
    "        elif provider == \"Anthropic\":\n",
    "            response = client.messages.create(\n",
    "                model=\"claude-2\",\n",
    "                max_tokens=1024,\n",
    "                messages=[{\"role\": \"user\", \"content\": augmented_prompt}]\n",
    "            )\n",
    "            token_usage = 1024  # Estimasi karena Anthropic tidak memberikan token usage\n",
    "            return response.content, token_usage\n",
    "\n",
    "        elif provider == \"Gemini\":\n",
    "            model = client.GenerativeModel(\"gemini-pro\")\n",
    "            response = model.generate_content(augmented_prompt)\n",
    "            token_usage = \"Tidak tersedia untuk Gemini\"  # Gemini tidak menyediakan token usage\n",
    "            return response.text, token_usage\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Terjadi kesalahan: {str(e)}\", 0\n",
    "\n",
    "# Chat Input\n",
    "prompt = st.chat_input(\"Masukkan prompt...\")\n",
    "if prompt:\n",
    "    client = set_provider(provider)\n",
    "    if client:\n",
    "        response, token_usage = get_response(provider, client, prompt, role, vector_store, prompt_laws, prompt_engineering)\n",
    "    else:\n",
    "        response, token_usage = \"Provider belum diatur.\", 0\n",
    "    \n",
    "    st.chat_message(\"user\").markdown(prompt)\n",
    "    st.chat_message(\"assistant\").markdown(response)\n",
    "\n",
    "    # Menampilkan token usage\n",
    "    if isinstance(token_usage, int):\n",
    "        st.info(f\"üìä Token digunakan: **{token_usage}**\")\n",
    "    else:\n",
    "        st.info(f\"üìä Token digunakan: **{token_usage}**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Memproses embedding untuk role: Laws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\WIN 10\\AppData\\Local\\Temp\\ipykernel_22016\\2317155241.py:53: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ö†Ô∏è Tidak ada data untuk diproses.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mcreate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLaws\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     create_embeddings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngineering\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 53\u001b[0m, in \u001b[0;36mcreate_embeddings\u001b[1;34m(role)\u001b[0m\n\u001b[0;32m     50\u001b[0m chunks \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_text(knowledge_base)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunks:\n\u001b[1;32m---> 53\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_texts(chunks, embedding\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Simpan FAISS ke file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:214\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     emit_warning()\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'model_kwargs': {}, 'cli...20, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
