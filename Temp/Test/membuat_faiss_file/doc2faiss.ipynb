{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile  # untuk membuat file ZIP\n",
    "import fitz  # PyMuPDF untuk membaca PDF\n",
    "from docx import Document  # Untuk membaca file DOCX\n",
    "import tiktoken  # Untuk menghitung token\n",
    "import io\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total token yang digunakan: 923\n",
      "✅ FAISS index telah disimpan di: Output_Faiss/faiss_index4\n",
      "✅ Daftar file telah disimpan di: Output_Faiss/faiss_index4\\file_list.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile  # untuk membuat file ZIP\n",
    "import fitz  # PyMuPDF untuk membaca PDF\n",
    "from docx import Document  # Untuk membaca file DOCX\n",
    "import tiktoken  # Untuk menghitung token\n",
    "import streamlit as st\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Memuat API Key dari .env\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Direktori penyimpanan FAISS Index\n",
    "FAISS_PATH = \"Output_Faiss\"\n",
    "\n",
    "# Fungsi membaca PDF\n",
    "def read_pdf(file_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:\n",
    "            text += page.get_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "# Fungsi membaca DOCX\n",
    "def read_docx(file_path):\n",
    "    doc = Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# Fungsi menghitung token\n",
    "def count_tokens(text, model=\"text-embedding-ada-002\"):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "# Fungsi untuk membuat folder dengan nama unik (faiss_index1, faiss_index2, dst)\n",
    "def create_unique_folder(path=FAISS_PATH):\n",
    "    # Pastikan direktori FAISS_PATH ada\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    # Cek folder dengan nama faiss_indexX yang tersedia\n",
    "    i = 1\n",
    "    while os.path.exists(f\"{path}/faiss_index{i}\"):\n",
    "        i += 1\n",
    "    # Buat folder baru dengan nama faiss_indexX yang tidak ada\n",
    "    unique_folder = f\"{path}/faiss_index{i}\"\n",
    "    os.makedirs(unique_folder)  # Pastikan folder dibuat\n",
    "    return unique_folder\n",
    "\n",
    "# Fungsi menyimpan FAISS ke file dan menyimpan daftar nama file dalam notepad\n",
    "def save_faiss_index(vector_store, file_list, combined_text, path=FAISS_PATH):\n",
    "    # Membuat folder baru dengan nama unik\n",
    "    index_folder = create_unique_folder(path)\n",
    "\n",
    "    # Simpan FAISS index\n",
    "    vector_store.save_local(index_folder)\n",
    "    print(f\"✅ FAISS index telah disimpan di: {index_folder}\")\n",
    "\n",
    "    # Simpan daftar file yang digunakan ke dalam file_list.txt\n",
    "    file_list_path = os.path.join(index_folder, \"file_list.txt\")\n",
    "    with open(file_list_path, \"w\") as f:\n",
    "        for file_name in file_list:\n",
    "            f.write(file_name + \"\\n\")\n",
    "    # Simpan combined_text ke dalam file combine_text.txt\n",
    "    file_list_path = os.path.join(index_folder, \"combine_text.txt\")\n",
    "\n",
    "    with open(file_list_path, \"w\") as f:\n",
    "        f.write(combined_text)  # Simpan seluruh combined_text ke dalam file\n",
    "    print(f\"✅ Daftar file telah disimpan di: {file_list_path}\")\n",
    "\n",
    "# Fungsi untuk memproses file yang di-upload\n",
    "def process_files(input_path, path=FAISS_PATH):\n",
    "    combined_text = \"\"\n",
    "    file_list = []\n",
    "\n",
    "    # Membaca file dari folder yang diberikan di input_path\n",
    "    if not os.path.exists(input_path):\n",
    "        raise ValueError(f\"Direktori atau file tidak ditemukan: {input_path}\")\n",
    "    \n",
    "    # Jika input adalah direktori\n",
    "    if os.path.isdir(input_path):\n",
    "        uploaded_files = []\n",
    "        for file_name in os.listdir(input_path):\n",
    "            file_path = os.path.join(input_path, file_name)\n",
    "            if file_name.endswith(\".pdf\"):\n",
    "                uploaded_files.append(file_path)\n",
    "        \n",
    "        # Proses file berdasarkan ekstensi\n",
    "        for file_path in uploaded_files:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            file_list.append(file_name)\n",
    "            combined_text += read_pdf(file_path) + \"\\n\"\n",
    "    else:\n",
    "        raise ValueError(\"Pastikan path yang diberikan adalah folder.\")\n",
    "\n",
    "    # Memecah teks menjadi chunks untuk FAISS\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = text_splitter.split_text(combined_text)\n",
    "\n",
    "    # Menghitung total token\n",
    "    total_tokens = sum(count_tokens(chunk) for chunk in chunks)\n",
    "    print(f\"Total token yang digunakan: {total_tokens}\")\n",
    "\n",
    "    # Membuat embedding dan FAISS\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "\n",
    "    # Simpan FAISS index\n",
    "    save_faiss_index(vector_store, file_list, combined_text)\n",
    "\n",
    "# Path file/folder yang ingin diproses\n",
    "input_folder_path = r'D:\\01. Bapak\\Github\\HazChat\\Temp\\Test\\membuat_faiss_file\\Input_file copy'\n",
    "\n",
    "# Memproses file dari folder\n",
    "process_files(input_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
